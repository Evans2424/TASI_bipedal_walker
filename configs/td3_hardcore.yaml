# TD3 Configuration for Bipedal Walker

# Environment settings
env:
  name: "BipedalWalker-v3"
  hardcore: true
  reward_scale: 1.0
  clip_observations: false
  clip_actions: true

# Agent settings
agent:
  type: "td3"
  hidden_dims: [256, 256]
  learning_rate: 3.0e-4
  gamma: 0.99
  tau: 0.005  # Soft update coefficient
  target_noise: 0.2  # Standard deviation of noise added to target actions
  noise_clip: 0.5  # Clipping range for target smoothing noise
  policy_update_freq: 2  # Update actor every N critic updates (delayed update)

# Replay buffer settings
buffer:
  capacity: 1000000
  batch_size: 256

# Training settings
training:
  total_timesteps: 2000000
  learning_starts: 10000  # Start training after this many steps
  train_frequency: 1  # Update every N steps
  gradient_steps: 1  # Number of gradient steps per update
  eval_frequency: 10000  # Evaluate every N steps
  eval_episodes: 10
  save_frequency: 50000  # Save checkpoint every N steps
  log_frequency: 1000  # Log metrics every N steps

# Exploration settings
exploration:
  initial_random_steps: 10000  # Pure random exploration initially

# Experiment settings
experiment:
  name: "td3_bipedal_walker_hardcore"
  seed: 42
  device: "cpu"  # "cuda", "mps" (for Mac M1/M2/M3), or "cpu"

# Paths
paths:
  checkpoints: "experiments/checkpoints"
  logs: "experiments/logs"
  videos: "experiments/videos"
